# Taming Big Data with Apache Spark

## Description

Learn to harness the power of Apache Spark and PySpark to analyze and process big data efficiently. All data for the exercises is located in the `data` folder.

## Getting Started

Follow these steps to set up your environment and start running Spark code:

**1. Clone the Repository**: To begin, clone this repository to your local machine using SSH:

```
git clone git@github.com:chithra-bhat/udemy-bigdata-with-spark.git
```

**2. Navigate to the Repository Folder**: Once the repository is cloned, change to the directory where it was cloned:

```
cd udemy-bigdata-with-spark
```

**3. Install Apache Spark**: Next, install Apache Spark by following the detailed installation instructions provided at [Sundog Education - Spark Python](https://www.sundog-education.com/spark-python/).

**4. Running Spark Code**: To execute Spark programs, use the `spark-submit` command. For example, to run a file named ratings-counter.py, use:

```
spark-submit ratings-counter.py
