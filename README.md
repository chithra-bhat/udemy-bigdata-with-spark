# Taming Big Data with Apache Spark

## Description

Learn to harness the power of Apache Spark and PySpark to analyze and process big data efficiently. All data for the exercises is located in the `data` folder.

## Getting Started

Follow these steps to set up your environment and start running Spark code:

- Clone the Repository: <br> To begin, clone this repository to your local machine using SSH:

```
git clone git@github.com:chithra-bhat/udemy-bigdata-with-spark.git
```

- Navigate to the Repository Folder: <br> Once the repository is cloned, change to the directory where it was cloned:

```
cd udemy-bigdata-with-spark
```

- Install Apache Spark: <br> Next, install Apache Spark by following the detailed installation instructions provided at [Sundog Education - Spark Python](https://www.sundog-education.com/spark-python/).

- Running Spark Code: <br> To execute Spark programs, use the `spark-submit` command. For example, to run a file named ratings-counter.py, use:

```
spark-submit ratings-counter.py
